import torch
from config.model_config import config
from src.pretrain.io.bert_processor import BertProcessor
from src.pretrain.model.bert_for_multi_label import BertForMultiLable
from src.utils.tools import convert_dict_to_list
from src.data_preprocessing.preprocess.preprocessor import EnglishPreProcessor
from argparse import ArgumentParser


def predict_n_keywords(text, arch, vocab_path, max_seq_length, do_lower_case, n, option):
	"""Predict the keywords with probability of occurence

	:param text: The abstract text from which keyword is to be generated.
	:param arch: The saved model to be used.
	:param vocab_path: The vocab path of model
	:param max_seq_length: Maximum sequence to be considered between [CLS] and [SEP]
	:param do_lower_case: whether the text should be made lower case
	:param n: Number of keywords to be generated
	:param option: The type of keywords we are extracting: term, most depth and mixed
	:return: Outputs n highest keywords.
	"""
	processor = BertProcessor(vocab_path=config[vocab_path], do_lower_case=do_lower_case, option=option)
	label_list = processor.get_labels()
	id2label = {i: label for i, label in enumerate(label_list)}
	model = BertForMultiLable.from_pretrained(config['checkpoint_dir'] /f'{arch}', num_labels=len(label_list))
	tokens = processor.tokenizer.tokenize(text)
	if len(tokens) > max_seq_length - 2:
		tokens = tokens[:max_seq_length - 2]
	tokens = ['[CLS]'] + tokens + ['[SEP]']
	input_ids = processor.tokenizer.convert_tokens_to_ids(tokens)
	input_ids = torch.tensor(input_ids).unsqueeze(0)  # Batch size 1, 2 choices
	logits = model(input_ids)
	probs = logits.sigmoid()	
	return give_n_highest_keywords(n, label_list, probs.cpu().detach().numpy()[0])
	

def give_n_highest_keywords(n, labels_list, probs):
	"""

	:param n: Number of keywords to be generated
	:param labels_list: labels list from vocab path
	:param probs: Probabilities generated by our model
	:return: Outputs n highest keywords.
	"""
	predicted_keywords = {}
	n_indices =  probs.argsort()[-n:][::-1]
	for i in n_indices:
		keyword = labels_list[i]
		prob = probs[i]
		predicted_keywords[keyword] = prob
	return str(convert_dict_to_list(predicted_keywords))

def main():
	parser = ArgumentParser()
	parser.add_argument("--text", type=str)
	parser.add_argument("--model", default='bert_term_30', type=str)
	parser.add_argument("--vocab_path", default='bert_vocab_path', type=str)
	parser.add_argument("--max_seq_length", default=512, type=int)
	parser.add_argument("--do_lower_case", default=True, type=bool)
	parser.add_argument("--n", default=10, type=int)
	parser.add_argument("--option", default='term', type=str)
	args = parser.parse_args()

	preprocessed_text = EnglishPreProcessor.preprocess(args.text)

	keywords = predict_n_keywords(preprocessed_text, args.model, args.vocab_path, args.max_seq_length, args.do_lower_case, args.n, args.option)
	print(keywords)

if __name__ == "__main__":
    main()
